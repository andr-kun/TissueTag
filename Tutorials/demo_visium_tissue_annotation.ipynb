{
 "cells": [
  {
   "cell_type": "code",
   "id": "5310a10ad3b05eaf",
   "metadata": {},
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a656df0f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# This notebook illustrates how to annotate a visium H&E image  \n",
    "\n",
    "\n",
    "In this notebook, we will annotate the visium H&E image extracted directly from the mapped 10X folder. \n",
    "We will load the image, and annotate it using various annotation tools. There are multiple options for image annotations: (1) fully-automatic - based on gene expression level, or (2) semi-automatic - based sparse manual labeling. Both (1) and (2) are used as a basis for prediction based on a pixel classifier. Finally,  we would finalise the image annotation based on manual annotation correction.\n",
    "Annotations will be saved with the extension .pkl."
   ]
  },
  {
   "cell_type": "code",
   "id": "recreational-notebook",
   "metadata": {
    "is_executing": true
   },
   "source": [
    "# initialisation \n",
    "import os\n",
    "import panel as pn\n",
    "import socket\n",
    "import numpy as np\n",
    "import tissue_tag as tt\n",
    "import tissue_tag.annotation\n",
    "\n",
    "os.environ[\"BOKEH_ALLOW_WS_ORIGIN\"] = \"*\"\n",
    "# host = '5011' # set the port to the value in the address bar when operating in farm\n",
    "host = '8888' # when working locally e.g. desktop"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "11679fba4e26b45e",
   "metadata": {},
   "source": [
    "# set path\n",
    "# here you can either read a single image (grayscale or RGB) or generate a virtual H&E from 2 images in the next cell\n",
    "Path = '../' #directory of tissuetag repo\n",
    "path = Path +'data/tissue_tag_minimal_example_visium/'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b103bb297616006b",
   "metadata": {},
   "source": [
    "# Step 1 - Create de-novo annotations from gene expression (or not)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126a4b9b662e80a9",
   "metadata": {},
   "source": [
    "Load a visium image and downscale it to a more manageable size. `res_in_ppm` is the desired pixels per micron in the output."
   ]
  },
  {
   "cell_type": "code",
   "id": "21471f91a0011e5e",
   "metadata": {},
   "source": "tt_object = tt.read_visium(spaceranger_dir_path=path, use_resolution='hires', in_tissue=True, ppm_out=0.5, plot=True)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c6d2db341c106808",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# define annotations \n",
    "annodict = {\n",
    "    'Medulla': 'green',\n",
    "    'Cortex': 'cyan',\n",
    "    'Edge': 'brown',\n",
    "    'HS': 'magenta',\n",
    "    'Vessels': 'blue',\n",
    "    'PVS': 'red',\n",
    "    'Other': 'orange'\n",
    "}\n",
    "tt_object.annotation_map = annodict"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a5cef71c2427bcb4",
   "metadata": {},
   "source": [
    "### Add semi automatic annotations based on gene expression \n",
    "In this option we wil use a simple random forest pixel classifier to call the cortex and medullar regions of the H&E image. The training labels will be derived based on the spots that show the highest expression of the marker gene."
   ]
  },
  {
   "cell_type": "code",
   "id": "e53b09b8a6675286",
   "metadata": {},
   "source": [
    "import scanpy\n",
    "adata = scanpy.read_visium(path, count_file='raw_feature_bc_matrix.h5')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4327709b7566fa82",
   "metadata": {},
   "source": [
    "gene_markers = {\n",
    "    'Medulla' : [('AIRE',30)], # AIRE is highly expressed in the medulla (the marker for medullar TEC type 2 cells)\n",
    "    'Cortex' : [('ARPP21',300)] # ARPP21 is highly expressed in the cortex\n",
    "}\n",
    "\n",
    "r = 35 # radius in microns for labels (27 is 1:1 label to visium spot - 55um diameter) but here i wanted to get some more context\n",
    "\n",
    "# generate training data from gene expression\n",
    "tissue_tag.annotation.gene_labels_from_adata(\n",
    "    adata=adata,\n",
    "    tissue_tag_annotation= tt_object,\n",
    "    gene_markers = gene_markers,\n",
    "    diameter = r*2,\n",
    "    override_labels=True,\n",
    "    normalize=False,\n",
    "    intensity_threshold=210 # Values may need to be changed depending on image\n",
    ") # generate gene-marker-labels\n",
    "\n",
    "tissue_tag.annotation.plot_labels(tt_object, alpha=0.5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d449cf87-dda4-4bce-a706-9c2a09f98166",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Part 2 - Iterative annotation section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6581dd6",
   "metadata": {},
   "source": [
    "At this stage, you can choose whether to use datashader - `use_datashader=True` for rendering the image (recommended for large images/high-resolution annotation). While the annotation process is slower with datashader, loading would be reasonable. If the image is too large, without datashader, the image might not load or take an extremely long time to load. \n",
    "\n",
    "Annotation is done by creating convex shapes in single strokes, the pixels inside the convex region would be filled in the `update_annotator` step. it's recommended to use a mouse with a wheel for easy scrolling in and out.\n",
    "*to remove a label the use can click on the label to remove and press the backspace key. "
   ]
  },
  {
   "cell_type": "code",
   "id": "3a8cc875-ae71-4960-9b8e-7036a2720b07",
   "metadata": {},
   "source": [
    "# use annotator to label tissue regions according to categories indicated above\n",
    "annotator = tissue_tag.annotation.annotator(tt_object, use_datashader=True)\n",
    "pn.io.notebook.show_server(annotator, notebook_url=f'localhost:'+host)\n",
    "#annotator.servable()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d1242afce02734bb",
   "metadata": {},
   "source": [
    "# This step fills in the shapes created for the pixel classifier\n",
    "tissue_tag.annotation.plot_labels(tt_object, alpha=0.5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9ff9dfc7f5249994",
   "metadata": {},
   "source": [
    "%%time\n",
    "# Train and predict the image pixels with a random forest classifier. This step takes about 1 to 10 min depending on number of training areas and resolution  \n",
    "test_tt_object = tissue_tag.annotation.pixel_label_classifier(tt_object, classifier=\"LogisticRegression\", threshold=0.9, downsampling_factor=4, plot=False, copy=True)\n",
    "tissue_tag.annotation.plot_labels(test_tt_object, alpha=0.5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "34e4887e-b756-4f50-8029-d1d764a4a52c",
   "metadata": {},
   "source": "From this point go back to the annotator and correct annotations untill happy with results."
  },
  {
   "cell_type": "markdown",
   "id": "5adf19e4-91c6-4afb-b9f0-97e4d35893dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Part 3 - Finalise annotations and save"
   ]
  },
  {
   "cell_type": "code",
   "id": "a5a70b3c-344a-4b3b-aadf-44c726f732f6",
   "metadata": {},
   "source": [
    "tissue_tag.annotation.plot_labels(tt_object, alpha=0.5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1e0a55ac",
   "metadata": {},
   "source": [
    "#  Save annotations (and load)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fossil-sigma",
   "metadata": {},
   "source": [
    "The resulting images and information can be saved for later use."
   ]
  },
  {
   "cell_type": "code",
   "id": "gross-powell",
   "metadata": {},
   "source": [
    "isExist = os.path.exists(path+'tissue_annotations')\n",
    "if not(isExist):\n",
    "    os.mkdir(path+'/tissue_annotations/')\n",
    "    \n",
    "tt_object.save_annotation(file_path=path+'/tissue_annotations/annotations.h5')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2085d02d",
   "metadata": {},
   "source": [
    "# optional - load annotations and as an intermediate step \n",
    "tt_object = tt.load_annotation(file_path=path + '/tissue_annotations/annotations.h5')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8ce423a1-6c93-4282-898e-97d9d8f16964",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
